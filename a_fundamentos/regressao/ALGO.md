# [üîô](../../README.md) Algor√≠timo de Regress√£o

## Vari√°veis

Independetes ou explorat√≥ria: √© a vari√°vel que explica o que queremos prever.
Dependentes: √© o que queremos prever.

![alt text](image-5.png)

![alt text](image-6.png)

![alt text](image-7.png)

Na regress√£o linear supoe que existe uma certa linearidade (n√£o perfeita) entre os valores. Matem√°tica diz que pode ser criado uma linha que se encaixe nos pontos (melhor ajuste). O modelo busca uma generaliza√ß√£o.

![alt text](image-8.png)

## Correla√ß√£o $R$
- Mostra a for√ßa e a dire√ß√£o da rela√ß√£o entre as vari√°veis.
- Poder ser um valor entre -1 e 1.
- A Correla√ß√£o de A~B √© a mesma que B~A.

![alt text](image-9.png)

Rela√ß√£o positiva como a do exemplo, maior idade mais caro. Ou rela√ß√£o negativa, como temperatura baixa aumenta o numero de vendas de casacos.
![alt text](image-10.png)


## Coeficiente de Determina√ß√£o $R^2$
![alt text](image-11.png)

Significa que 86% pode ser explicada pela vari√°vel Idade, mas 14% s√£o explicadas por vari√°veis n√£o presentes no modelo.
![alt text](image-12.png)

## Como a linha √© constru√≠da?

Regra de linear. ax + b = y.

![alt text](image-13.png)
![alt text](image-14.png)

## Como prever?
![alt text](image-15.png)

## Zoom

Observe que os pontos podem n√£o bater com a linha. H√° res√≠duos de erros. Acima s√£o erros positivos e abaixo da linha s√£o erros negativos.
![alt text](image-16.png)


![alt text](image-17.png)


## Tipos de Regress√£o

- **Simples**: Uma vari√°vel explanat√≥ria para prever uma vari√°vel dependente. 
$$Y\sim X$$

- **M√∫ltipla**: Duas ou mais vari√°veis explanat√≥rias para para prever uma vari√°vel dependente. 
    $$Y\sim X1 + X2 + X3 + ...$$


## Condi√ß√µes de Regress√£o simples

N√£o se pode fazer regress√£o sem considerar algumas condi√ß√µes m√≠nimas para isso.

- Correla√ß√£o: Moderada/Forte.
- Coficiente de determina√ß√£o $R^2$: 
    - $R^2 \geq 0.7$ - Bom desempenho.	
    - Entre eles: Precisa ser avaliado
    - $0 \leq R^2 \leq 0.3 $ - Ruim desempenho.

- Residuais proximos de uma distribui√ß√£o normal. 
    - Histogramas
    - Diagrama de normalidade (Normal Q-Q Plot)
    - Teste de normalidade (Shapiro-Wilk)

## Condi√ß√µes de Regress√£o m√∫ltiplas

- Analisar cada vari√°vel independente com $Y$ individualmente
- Gerar gr√°ficos de dispers√£o individuais
- Buscar redund√™ncias (mesmos efeitos de $X$ sobre $Y$)
- Linearidade entre a vari√°vel dependente e as vari√°veis independentes

- Coficiente de determina√ß√£o $R^2$:
    - Lembrando que o $R^2$ √© o percentual de varia√ß√£o da vari√°vel de resposta que √© explicada pelo modelo.
    - Quando se colocam mais vari√°veis no modelo, a tend√©ncia √© de aumentar o $R^2$, mesmo que a adi√ß√£o de vari√°veis nao aumente a qualidade/precis√£o do modelo.
    - Deve-se utilizar o $R^2_{ajustado}$` , que ajusta a varia√ß√£o do modelo de acordo com o n√∫mero de vari√°veis independentes inclu√≠das no modelo.
    - O $R^2_{ajustado}$ var ser sempre menor que o $R^2$.

- Colinearidade:
    - Correla√ß√£o forte entre vari√°veis independentes.
    - Multicolinearidade: corre√ß√£o entre as vari√°veis independentes
    - Incluir vari√°veis independentes colineares pode prejudicar o modelo, criando previs√µes erradas.
    - Pouca ou nenhuma colinearidade;
    - Solu√ß√£o: Excluir um dos atributos ou combinar colunas bin√°rias.

- Parcim√¥nia:
    - N√£o colocaor vari√°veis que n√£o melhorem o modelo em nada. Criar modelos parcimoniosos.

- Res√≠duos:
    - pr√≥ximos a distribui√ß√£o normal
    - vari√¢ncia constante em rela√ß√£o a linha de melhor ajuste
    - Independentes (sem padr√£o)

- Uso de Correlograma √© sugestiva.
![alt text](image-18.png)


## C√°lculos

```mermaid
flowchart LR
    r[Correla√ß√£o]-->m[Inclina√ß√£o]
    m-->b[Intercepta√ß√£o]
    b-->p[Previs√£o]
```

### Correla√ß√£o $r$

Pearson √© a mais comum.
![alt text](image-19.png)
> Valor pr√≥xima de 1 (bem forte) e positiva


### Inclina√ß√£o $m$

$S_y$ e $S_x$ s√£o desvios padr√£o de $Y$ e $X$ respectivamente.
![alt text](image-20.png)

### Intercepta√ß√£o $b$
![alt text](image-21.png)

### Previs√£o $p$

$$p = b + (m * v)$$

![alt text](image-22.png)